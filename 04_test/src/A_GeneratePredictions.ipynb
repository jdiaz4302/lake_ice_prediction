{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f865d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/software/common/arc/apps/jupyter/conda/envs/jupyter3.4/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf7a59e",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257dd83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_out_dir = '01_process/out/'\n",
    "\n",
    "soft_test_fpath = process_out_dir + 'soft_test_data.npz'\n",
    "test_fpath = process_out_dir + 'test_data.npz'\n",
    "\n",
    "\n",
    "train_out_dir = '02_train/out/'\n",
    "\n",
    "data_scalars_fpath =  train_out_dir + 'massive_lstm_min_max_scalars_1_.pt'\n",
    "model_weights_fpath = train_out_dir + 'massive_lstm_weights_1_.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe77fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_dir = '/caldera/projects/usgs/water/iidd/datasci/lake-temp/lake_ice_prediction/'\n",
    "\n",
    "soft_test_fpath = extended_dir + soft_test_fpath\n",
    "test_fpath = extended_dir + test_fpath\n",
    "\n",
    "data_scalars_fpath = extended_dir + data_scalars_fpath\n",
    "model_weights_fpath = extended_dir + model_weights_fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d81d796",
   "metadata": {},
   "source": [
    "### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41604966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparams\n",
    "if 'massive_lstm' in data_scalars_fpath:\n",
    "    params = 18920961 # matching the full size, encoder only, transformer\n",
    "    model_dim = int(np.round((1/88)*(np.sqrt(176*params + 4585) - 69))) # assumes 11 variables \n",
    "    # ^ solves for y where y = 4x^2 + 49x + 1\n",
    "    # which was originally y = 11*4*x + 4*x*x + 4*x + 1*x + 1\n",
    "    dropout_val = 0.1 # matching encoder default value\n",
    "    nlayers = 6\n",
    "    bs = 375\n",
    "elif 'avg_lstm' in data_scalars_fpath:\n",
    "    model_dim = 16\n",
    "    dropout_val = 0.1 # matching encoder default value\n",
    "    nlayers = 1\n",
    "    bs = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c0c69f-66c0-41a1-8d72-29f7c6fe3ac0",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acb8f35-95ca-4642-9a4f-1d0c566b983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_dir = '04_test/out/'\n",
    "\n",
    "soft_test_preds_fpath = test_out_dir + 'massive_lstm_soft_test_preds_1_.npy'\n",
    "test_preds_fpath = test_out_dir + 'massive_lstm_test_preds_1_.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55b27b3-0a3f-4f5a-bc2a-3af5d2eb405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_test_preds_fpath = extended_dir + soft_test_preds_fpath\n",
    "test_preds_fpath = extended_dir + test_preds_fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de0acb",
   "metadata": {},
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd15cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_test = np.load(soft_test_fpath, allow_pickle = True)\n",
    "test = np.load(test_fpath, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e33cef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_test_x = torch.from_numpy(soft_test['x']).float()\n",
    "test_x = torch.from_numpy(test['x']).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff0a627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scalars = torch.load(data_scalars_fpath)\n",
    "\n",
    "for i in range(soft_test_x.shape[2]):\n",
    "    # scale soft test set with train min/max\n",
    "    soft_test_x[:, :, i] = ((soft_test_x[:, :, i] - min_max_scalars[i, 0]) /\n",
    "                            (min_max_scalars[i, 1] - min_max_scalars[i, 0]))\n",
    "    \n",
    "    # scale test set with train min/max\n",
    "    test_x[:, :, i] = ((test_x[:, :, i] - min_max_scalars[i, 0]) /\n",
    "                       (min_max_scalars[i, 1] - min_max_scalars[i, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a248ac9e",
   "metadata": {},
   "source": [
    "# Define and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a50a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "                            num_layers = nlayers,\n",
    "                            batch_first = True)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        \n",
    "        drop_out = self.dropout(lstm_out)\n",
    "        \n",
    "        out = self.activation(self.dense(drop_out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c45445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicLSTM(soft_test_x.shape[2], model_dim, nlayers, dropout_val).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30eb898e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_weights_fpath)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8bb45",
   "metadata": {},
   "source": [
    "# Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ba8895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using the data loader is simpler for variable Shuffle=True/False\n",
    "# (and I implemented this prior to using formal data loaders)\n",
    "def generate_all_preds_via_batch(x_tensor, batch_size):\n",
    "    # make empty array for predictions\n",
    "    y_hat_tensor = torch.zeros([x_tensor.shape[0], x_tensor.shape[1], 1])\n",
    "    \n",
    "    # until we use all the possible sequential batches...\n",
    "    count = 1\n",
    "    loop_max = int(np.ceil(x_tensor.shape[0] / batch_size))\n",
    "    for i in range(loop_max):\n",
    "        min_i = (count-1)*bs\n",
    "        max_i = count*bs\n",
    "        # generate batch-sized predictions\n",
    "        if i != (loop_max - 1):\n",
    "            with torch.no_grad():\n",
    "                y_hat_tensor[min_i:max_i] = model(x_tensor[min_i:max_i].cuda()).cpu()\n",
    "        # or remaining-sized predictions\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat_tensor[min_i:] = model(x_tensor[min_i:].cuda()).cpu()\n",
    "        # update batch count\n",
    "        count += 1\n",
    "        \n",
    "    return y_hat_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c839158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_test_y_hat = generate_all_preds_via_batch(soft_test_x, bs)\n",
    "test_y_hat = generate_all_preds_via_batch(test_x, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63321707",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(soft_test_preds_fpath, soft_test_y_hat.numpy())\n",
    "np.save(test_preds_fpath, test_y_hat.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc561b-90da-499c-a18d-f6e690b57cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
