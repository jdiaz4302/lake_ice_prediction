{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99154803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/software/common/arc/apps/jupyter/conda/envs/jupyter3.4/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fae7d1",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a05ad45",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1831c88a-33e7-41c5-8b3d-69f0238e0e2c",
   "metadata": {},
   "source": [
    "# USE THIS \n",
    "process_out_dir = '01_process/out/'\n",
    "\n",
    "train_data_fpath = process_out_dir + 'train_data.npz'\n",
    "valid_data_fpath = process_out_dir + 'valid_data.npz'\n",
    "\n",
    "train_out_dir = '02_train/out/'\n",
    "\n",
    "data_scalars_fpath =  train_out_dir + 'avg_lstm_min_max_scalars_3_.pt'\n",
    "model_weights_fpath = train_out_dir + 'avg_lstm_weights_3_.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eb61594-6bb6-4545-857c-8e9d56404476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR THIS\n",
    "process_out_dir = '01_process/out/'\n",
    "\n",
    "train_data_fpath = process_out_dir + 'train_data.npz'\n",
    "valid_data_fpath = process_out_dir + 'valid_data.npz'\n",
    "\n",
    "train_out_dir = '02_train/out/'\n",
    "\n",
    "data_scalars_fpath =  train_out_dir + 'massive_lstm_min_max_scalars_1_.pt'\n",
    "model_weights_fpath = train_out_dir + 'massive_lstm_weights_1_.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be129ec-1f8b-4221-9557-bbcf84fcc6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_dir = '/caldera/projects/usgs/water/iidd/datasci/lake-temp/lake_ice_prediction/'\n",
    "\n",
    "train_data_fpath = extended_dir + train_data_fpath\n",
    "valid_data_fpath = extended_dir + valid_data_fpath\n",
    "data_scalars_fpath = extended_dir + data_scalars_fpath\n",
    "model_weights_fpath = extended_dir + model_weights_fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727e963e",
   "metadata": {},
   "source": [
    "### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971a4ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparams\n",
    "if 'massive_lstm' in data_scalars_fpath:\n",
    "    params = 18920961 # matching the full size, encoder only, transformer\n",
    "    model_dim = int(np.round((1/88)*(np.sqrt(176*params + 4585) - 69))) # assumes 11 variables \n",
    "    # ^ solves for y where y = 4x^2 + 49x + 1\n",
    "    # which was originally y = 11*4*x + 4*x*x + 4*x + 1*x + 1\n",
    "    dropout_val = 0.1 # matching encoder default value\n",
    "    nlayers = 6\n",
    "    bs = 375\n",
    "elif 'avg_lstm' in data_scalars_fpath:\n",
    "    model_dim = 16\n",
    "    dropout_val = 0.1 # matching encoder default value\n",
    "    nlayers = 1\n",
    "    bs = 5000\n",
    "    \n",
    "# when deriving the max ice on date, one detail is that\n",
    "# we must omit the late ice on dates that occur during a\n",
    "# (predicted) rethaw. This value is a temporal index\n",
    "# representing the maximum day after July 1 that can\n",
    "# be a considered a max ice on date.\n",
    "# A value of 215 equates to February 1\n",
    "ice_on_cutoff = 215\n",
    "\n",
    "eval_seed = 0\n",
    "### FOR METHOD 1: Expected Gradients ###\n",
    "# Number of validation samples to calculate EG for\n",
    "n_eg = 50\n",
    "# Number of validation samples for finer eval\n",
    "# (looking at EG with temporal focus on transition dates)\n",
    "n_eg_fine = 30\n",
    "# Number of EG algorithm samples (per call to that funct)\n",
    "eg_samples = 200 \n",
    "\n",
    "### FOR METHOD 2: Permutation-based ###\n",
    "# Number of times to scramble the data for all validation samples\n",
    "perm_samples = 200\n",
    "\n",
    "### FOR METHOD 3: Individual conditional expectation ###\n",
    "resolution =  25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335ca09f",
   "metadata": {},
   "source": [
    "### Outputs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99671ff1-f1a5-484b-aa7f-351380f9dde0",
   "metadata": {},
   "source": [
    "# USE THIS\n",
    "eval_out_dir = '03_eval/out/'\n",
    "\n",
    "rand_valid_set_EGs_fpath = eval_out_dir + 'avg_lstm_random_valid_eg_coarse_3_.npz'\n",
    "rand_valid_ice_on_EGs_fpath = eval_out_dir + 'avg_lstm_random_valid_eg_ice_on_3_.npz'\n",
    "rand_valid_ice_off_EGs_fpath = eval_out_dir + 'avg_lstm_random_valid_eg_ice_off_3_.npz'\n",
    "\n",
    "valid_set_permutation_fpath = eval_out_dir + 'avg_lstm_permutation_results_3_.npy'\n",
    "\n",
    "valid_set_ICE_vals_fpath = eval_out_dir + 'avg_lstm_valid_ICE_vals_3_.npy'\n",
    "valid_set_ICE_preds_fpath = eval_out_dir + 'avg_lstm_valid_ICE_preds_3_.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d02c4d-f3c1-4eab-a1a0-fdd8e78a0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR THIS\n",
    "eval_out_dir = '03_eval/out/'\n",
    "\n",
    "rand_valid_set_EGs_fpath = eval_out_dir + 'massive_lstm_random_valid_eg_coarse_1_.npz'\n",
    "rand_valid_ice_on_EGs_fpath = eval_out_dir + 'massive_lstm_random_valid_eg_ice_on_1_.npz'\n",
    "rand_valid_ice_off_EGs_fpath = eval_out_dir + 'massive_lstm_random_valid_eg_ice_off_1_.npz'\n",
    "\n",
    "valid_set_permutation_fpath = eval_out_dir + 'massive_lstm_permutation_results_1_.npy'\n",
    "\n",
    "valid_set_ICE_vals_fpath = eval_out_dir + 'massive_lstm_valid_ICE_vals_1_.npy'\n",
    "valid_set_ICE_preds_fpath = eval_out_dir + 'massive_lstm_valid_ICE_preds_1_.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac144d9d-2a16-4b61-91c6-431f37baf4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_valid_set_EGs_fpath = extended_dir + rand_valid_set_EGs_fpath\n",
    "rand_valid_ice_on_EGs_fpath = extended_dir + rand_valid_ice_on_EGs_fpath\n",
    "rand_valid_ice_off_EGs_fpath = extended_dir + rand_valid_ice_off_EGs_fpath\n",
    "\n",
    "valid_set_permutation_fpath = extended_dir + valid_set_permutation_fpath\n",
    "\n",
    "valid_set_ICE_vals_fpath = extended_dir + valid_set_ICE_vals_fpath\n",
    "valid_set_ICE_preds_fpath = extended_dir + valid_set_ICE_preds_fpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2143bb1-b322-44c4-a252-1145d4887ab3",
   "metadata": {},
   "source": [
    "# Quick check that files match up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0aae99c-51d7-4c9c-9d9b-c8549bc5b238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lump all files together\n",
    "files = [data_scalars_fpath, model_weights_fpath,\n",
    "         rand_valid_set_EGs_fpath, rand_valid_ice_on_EGs_fpath,\n",
    "         rand_valid_ice_off_EGs_fpath, valid_set_permutation_fpath,\n",
    "         valid_set_ICE_vals_fpath, valid_set_ICE_preds_fpath]\n",
    "\n",
    "# extract their specified size and seed value\n",
    "file_model_sizes = []\n",
    "file_model_seeds = []\n",
    "for file in files:\n",
    "    file_model_sizes.append(file.split('_')[3].split('/')[-1])\n",
    "    file_model_seeds.append(file.split('_')[-2])\n",
    "    \n",
    "# make sure only 1 unique size and seed exists among files\n",
    "assert len(np.unique(np.asarray(file_model_sizes))) == 1\n",
    "assert len(np.unique(np.asarray(file_model_seeds))) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dec7db",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa08884",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(train_data_fpath, allow_pickle = True)\n",
    "valid_data = np.load(valid_data_fpath, allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18afb480",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8930150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = valid_data['x']\n",
    "valid_y = valid_data['y']\n",
    "valid_variables = valid_data['features']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d323f5",
   "metadata": {},
   "source": [
    "# Scale and format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de86cd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.from_numpy(train_x).float()\n",
    "\n",
    "valid_y = torch.from_numpy(valid_y).float().unsqueeze(2)\n",
    "valid_x = torch.from_numpy(valid_x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6ff636",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scalars = torch.load(data_scalars_fpath)\n",
    "\n",
    "for i in range(train_x.shape[2]):\n",
    "    # scale train set with train min/max\n",
    "    train_x[:, :, i] = ((train_x[:, :, i] - min_max_scalars[i, 0]) /\n",
    "                        (min_max_scalars[i, 1] - min_max_scalars[i, 0]))\n",
    "    # scale valid set with train min/max\n",
    "    valid_x[:, :, i] = ((valid_x[:, :, i] - min_max_scalars[i, 0]) /\n",
    "                        (min_max_scalars[i, 1] - min_max_scalars[i, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f889d70",
   "metadata": {},
   "source": [
    "# Load trained model (with all vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fbd6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, nlayers, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim,\n",
    "                            num_layers = nlayers,\n",
    "                            batch_first = True)\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        \n",
    "        self.dense = nn.Linear(hidden_dim, 1)\n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        lstm_out, (h, c) = self.lstm(x)\n",
    "        \n",
    "        drop_out = self.dropout(lstm_out)\n",
    "        \n",
    "        out = self.activation(self.dense(drop_out))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "583e1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicLSTM(train_x.shape[2], model_dim, nlayers, dropout_val).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "801669c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_weights_fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a7ca0-f15f-4faa-ae93-a556036b72f6",
   "metadata": {},
   "source": [
    "# Set up a seeded random generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3987c76b-ec67-405d-991c-b486e5728629",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNG = np.random.RandomState(eval_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70838f",
   "metadata": {},
   "source": [
    "# Set up expected gradients (EG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab090801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_gradients(x, x_set, model, n_samples, rng, temporal_focus=None, spatial_focus=None):\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    n_seq = x_set.shape[0]\n",
    "    seq_len = x_set.shape[1]\n",
    "    num_vars = x_set.shape[2]\n",
    "\n",
    "    for k in range(n_samples):\n",
    "        # SAMPLE A RANDOM BASELINE INPUT\n",
    "        rand_seq = rng.choice(n_seq) # rand_time may be more accurate\n",
    "        baseline_x = x_set[[rand_seq]].to(device)\n",
    "\n",
    "        # SAMPLE A RANDOM SCALE ALONG THE DIFFERENCE\n",
    "        scale = rng.uniform()\n",
    "\n",
    "        # SAME IG CALCULATION\n",
    "        x_diff = x - baseline_x\n",
    "        curr_x = baseline_x + scale*x_diff\n",
    "        if curr_x.requires_grad == False:\n",
    "            curr_x.requires_grad = True\n",
    "        model.zero_grad()\n",
    "        y = model(curr_x)\n",
    "\n",
    "        # GET GRADIENT\n",
    "        if temporal_focus == None and spatial_focus == None:\n",
    "            gradients = torch.autograd.grad(y[:, :, :], curr_x, torch.ones_like(y[:, :, :]))\n",
    "        elif temporal_focus == None and spatial_focus != None:\n",
    "            gradients = torch.autograd.grad(y[spatial_focus, :, :], curr_x, torch.ones_like(y[spatial_focus, :, :]))\n",
    "        elif temporal_focus != None and spatial_focus == None:\n",
    "            gradients = torch.autograd.grad(y[:, temporal_focus, :], curr_x, torch.ones_like(y[:, temporal_focus, :]))\n",
    "        else:\n",
    "            gradients = torch.autograd.grad(y[spatial_focus, temporal_focus, :], curr_x, torch.ones_like(y[spatial_focus, temporal_focus, :]))\n",
    "\n",
    "        if k == 0:\n",
    "            expected_gradients = x_diff*gradients[0] * 1/n_samples\n",
    "        else:\n",
    "            expected_gradients = expected_gradients + ((x_diff*gradients[0]) * 1/n_samples)\n",
    "\n",
    "    return(expected_gradients.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d43e666",
   "metadata": {},
   "source": [
    "# Perform EG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bada95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array to store expected gradient results\n",
    "valid_eg_results = np.zeros([n_eg, valid_x.shape[1], valid_x.shape[2]])\n",
    "# List to store the sampled validation indices\n",
    "sampled_valid_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "593013b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 9s, sys: 17min 40s, total: 51min 49s\n",
      "Wall time: 25min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(n_eg):\n",
    "    # Pick a random validation sample and record it\n",
    "    rand_valid_i = RNG.choice(valid_x.shape[0])\n",
    "    sampled_valid_ids.append(rand_valid_i)\n",
    "    \n",
    "    # Calc expected gradients and store them\n",
    "    eg_vals = expected_gradients(valid_x[[rand_valid_i]].cuda(), train_x, model, eg_samples, RNG)\n",
    "    valid_eg_results[[i]] = eg_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d85f0cc",
   "metadata": {},
   "source": [
    "# Evaluate EGs w.r.t. ice transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f593948b-bc6f-4382-9a36-4a2224c67dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using the data loader is simpler for variable Shuffle=True/False\n",
    "# (and I implemented this prior to using formal data loaders)\n",
    "def generate_all_preds_via_batch(x_tensor, batch_size):\n",
    "    # make empty array for predictions\n",
    "    y_hat_tensor = torch.zeros([x_tensor.shape[0], x_tensor.shape[1], 1])\n",
    "    \n",
    "    # until we use all the possible sequential batches...\n",
    "    count = 1\n",
    "    loop_max = int(np.ceil(x_tensor.shape[0] / batch_size))\n",
    "    for i in range(loop_max):\n",
    "        min_i = (count-1)*bs\n",
    "        max_i = count*bs\n",
    "        # generate batch-sized predictions\n",
    "        if i != (loop_max - 1):\n",
    "            with torch.no_grad():\n",
    "                y_hat_tensor[min_i:max_i] = model(x_tensor[min_i:max_i].cuda()).cpu()\n",
    "        # or remaining-sized predictions\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                y_hat_tensor[min_i:] = model(x_tensor[min_i:].cuda()).cpu()\n",
    "        # update batch count\n",
    "        count += 1\n",
    "        \n",
    "    return y_hat_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63e1b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_y_hat = generate_all_preds_via_batch(valid_x, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81b8496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine when we predict an ice-free to ice-on transition\n",
    "diff_valid_y_hat = np.diff(np.round(valid_y_hat), axis = 1)\n",
    "\n",
    "# objects to store in\n",
    "transition_ids_ice_on = np.zeros([valid_x.shape[0], 1])\n",
    "transition_ids_ice_off = np.zeros([valid_x.shape[0], 1])\n",
    "\n",
    "# loop through all sequences\n",
    "for i in range(valid_x.shape[0]):\n",
    "    \n",
    "    seq_of_interest = diff_valid_y_hat[i].flatten()\n",
    "    \n",
    "    # identify last freeze before cut off where spring thawing starts\n",
    "    ice_on_id =  np.argwhere(seq_of_interest == 1)[np.argwhere(seq_of_interest == 1) < ice_on_cutoff][-1].item()\n",
    "    # identify last thaw\n",
    "    ice_off_id =  np.argwhere(seq_of_interest == -1)[-1].item()\n",
    "    \n",
    "    transition_ids_ice_on[i] = ice_on_id\n",
    "    transition_ids_ice_off[i] = ice_off_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe57071",
   "metadata": {},
   "source": [
    "### Ice on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "968b6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage objects\n",
    "valid_eg_results_ice_on = np.zeros([n_eg_fine, valid_x.shape[1], valid_x.shape[2]])\n",
    "sampled_valid_ids_ice_on = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "432c3781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 10s, sys: 10min 27s, total: 30min 37s\n",
      "Wall time: 15min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for a few predictions, look at EG values focused on that predicted transition\n",
    "for i in range(n_eg_fine):\n",
    "    # Pick a random validation sample and record it\n",
    "    rand_valid_i = RNG.choice(valid_x.shape[0])\n",
    "    sampled_valid_ids_ice_on.append(rand_valid_i)\n",
    "    \n",
    "    # Calc expected gradients and store them\n",
    "    eg_vals = expected_gradients(valid_x[[rand_valid_i]].cuda(), train_x, model, eg_samples, RNG,\n",
    "                                 temporal_focus = transition_ids_ice_on[rand_valid_i])\n",
    "    valid_eg_results_ice_on[[i]] = eg_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6d0bc",
   "metadata": {},
   "source": [
    "### Ice off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "839dad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage objects\n",
    "valid_eg_results_ice_off = np.zeros([n_eg_fine, valid_x.shape[1], valid_x.shape[2]])\n",
    "sampled_valid_ids_ice_off = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56393ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 2s, sys: 10min 23s, total: 30min 26s\n",
      "Wall time: 15min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for a few predictions, look at EG values focused on that predicted transition\n",
    "for i in range(n_eg_fine):\n",
    "    # Pick a random validation sample and record it\n",
    "    rand_valid_i = RNG.choice(valid_x.shape[0])\n",
    "    sampled_valid_ids_ice_off.append(rand_valid_i)\n",
    "    \n",
    "    # Calc expected gradients and store them\n",
    "    eg_vals = expected_gradients(valid_x[[rand_valid_i]].cuda(), train_x, model, eg_samples, RNG,\n",
    "                                 temporal_focus = transition_ids_ice_off[rand_valid_i])\n",
    "    valid_eg_results_ice_off[[i]] = eg_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d4976",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "# Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3e00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4dca0673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06356417387723923"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_y_hat = generate_all_preds_via_batch(valid_x, bs)\n",
    "base_loss = loss_fn(valid_y_hat, valid_y)\n",
    "base_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0499323f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26min 29s, sys: 21min 37s, total: 48min 6s\n",
      "Wall time: 33min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "permutation_results =  np.zeros([perm_samples, len(valid_variables)])\n",
    "\n",
    "for n_i in range(perm_samples):\n",
    "    ids = np.arange(valid_x.shape[0])\n",
    "    # an in-place operation\n",
    "    RNG.shuffle(ids)\n",
    "\n",
    "    loss_ls = []\n",
    "    for var_i in range(len(valid_variables)):\n",
    "        perm_valid_x = valid_x.clone()\n",
    "        perm_valid_x[:, :, var_i] = valid_x[ids, :, var_i]\n",
    "        with torch.no_grad():\n",
    "            perm_valid_y_hat = generate_all_preds_via_batch(perm_valid_x, bs)\n",
    "            loss = loss_fn(perm_valid_y_hat, valid_y)\n",
    "        loss_ls.append(loss.item())\n",
    "        \n",
    "    permutation_results[n_i] = loss_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912188f2-13ad-4ecb-898c-2939600ba3e5",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "# ICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93ffb611-3da4-4bab-9164-3dadae73ca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ICE_x_array = np.zeros([len(valid_variables), resolution + 3])\n",
    "ICE_pred_array = np.zeros([len(valid_variables), resolution + 3, valid_x.shape[0], valid_x.shape[1], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "565f6295-72ba-4794-bc70-d1314fd63eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_index in range(len(valid_variables)):\n",
    "    \n",
    "    # Generate a grid of values to make predictions over for each variable\n",
    "    # get values to change inputs to\n",
    "    grid_quantiles = np.arange(0, 1 + 1/resolution, 1/resolution)\n",
    "    grid_values = np.quantile(train_x[:, :, var_index].numpy().flatten(), grid_quantiles)\n",
    "    \n",
    "    # add some out-of-bound, extreme values\n",
    "    lower_extreme_tail_val = grid_values[0] - (grid_values[1] - grid_values[0])\n",
    "    upper_extreme_tail_val = grid_values[-1] + (grid_values[-1] - grid_values[-2])\n",
    "    \n",
    "    # put everything together\n",
    "    grid_values = np.insert(grid_values, 0, lower_extreme_tail_val)\n",
    "    grid_values = np.append(grid_values, upper_extreme_tail_val)\n",
    "    \n",
    "    \n",
    "    # Generate predictions\n",
    "    val_count = 0\n",
    "    for val in grid_values:\n",
    "        cur_x = valid_x.clone()\n",
    "        cur_x[:, :, var_index] = torch.as_tensor(val)\n",
    "        cur_y_hat = generate_all_preds_via_batch(cur_x, bs)\n",
    "        \n",
    "        # Store val and pred\n",
    "        ICE_x_array[var_index, val_count] = val\n",
    "        ICE_pred_array[var_index, val_count] = cur_y_hat\n",
    "        val_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee8dd8-16c6-40e7-9389-60061ed87f82",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3610582c-059c-4b42-9143-edfe4754db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_eg_results_bundled = {'results':valid_eg_results,\n",
    "                            'ids':sampled_valid_ids}\n",
    "\n",
    "valid_eg_results_ice_on_bundled = {'results':valid_eg_results_ice_on,\n",
    "                                   'ids':sampled_valid_ids_ice_on}\n",
    "\n",
    "valid_eg_results_ice_off_bundled = {'results':valid_eg_results_ice_off,\n",
    "                                    'ids':sampled_valid_ids_ice_off}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03b3f110-c820-4e63-b0fe-08cd56f2d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(rand_valid_set_EGs_fpath, **valid_eg_results_bundled)\n",
    "np.savez_compressed(rand_valid_ice_on_EGs_fpath, **valid_eg_results_ice_on_bundled)\n",
    "np.savez_compressed(rand_valid_ice_off_EGs_fpath, **valid_eg_results_ice_off_bundled)\n",
    "\n",
    "np.save(valid_set_permutation_fpath, permutation_results)\n",
    "\n",
    "np.save(valid_set_ICE_vals_fpath, ICE_x_array)\n",
    "np.save(valid_set_ICE_preds_fpath, ICE_pred_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e63451a-40c5-4308-b6d8-8c025912a15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
